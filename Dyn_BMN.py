# -*- coding: utf-8 -*-
"""Dyn_BMN.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1au75KCEMNdSldamGkhjPmGnCNWVZZzHA
"""

import random as rn
import numpy as np
from typing import no_type_check_decorator

import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib
import random

from scipy.integrate import ode
from scipy.integrate import solve_ivp
from scipy.interpolate import interp1d

import matplotlib
from matplotlib.patches import Patch

#GENERATES THE MATRIX OF S states

# adapted from gen_A in BalloonModelNet
# FOR few ROIs
def gen_A(N_nds=5, N_conn=3, seed = None, sym=False):
    A = np.eye(N_nds)
    node_pairs = []
    for i in range(N_nds):
        for j in range(N_nds):
            if i > j:
                node_pairs.append( (i,j) )

    rn.seed(seed)
    nodes_connected = []
    while len(nodes_connected)<N_conn:
        n = rn.choice( node_pairs )
        if n not in nodes_connected:
            nodes_connected.append( n )
    for i, j in nodes_connected:
        A[i, j] = rn.choice(np.arange(0.65,0.90,0.01))

    if sym: # sym is True, the matrix is symetric
        A = A + A.T - np.diag(A.diagonal())

    return A
# Generate conectivity matrices for each state
def gen_states_A(S, D, N_conns, sym=False, seed=None):
    As = []
    for i in range(S):
        if seed == None:
            A = gen_A(N_nds=D, N_conn=N_conns[i], seed=seed, sym=sym)
        else:
            A = gen_A(N_nds=D, N_conn=N_conns[i], seed=seed, sym=sym)
            seed += 5
        As.append(A)
    #print(As)
    return np.array(As)

# FOR more than 30 ROIs 
def gen_modular_A(N_nds=90,
                  n_modules_diag=6,
                  n_extra_per_module=3,  
                  intra_range=(0.6, 1.0),
                  seed=None,
                  sym=True):

    if seed is not None:
        rn.seed(seed)
        np.random.seed(seed)

    A = np.eye(N_nds)

    # Generates sizes of modules
    A_max = rn.randint(int(N_nds * 0.75), N_nds)
    sizes = np.random.multinomial(A_max, [1/n_modules_diag]*n_modules_diag)

    # Initial positions
    start_positions = sorted(
        np.random.choice(np.arange(N_nds), n_modules_diag, replace=False)
    )

    order = np.argsort(sizes)[::-1] # Larger modules first
    modules = []
    used = np.zeros(N_nds, dtype=bool)

    # Contiguous modules
    for k in order:
        size = sizes[k]
        placed = False
        for start in start_positions:
            if start + size <= N_nds and not used[start:start+size].any():
                modules.append(list(range(start, start+size)))
                used[start:start+size] = True
                placed = True
                break

        if not placed:
            # fallback
            for start in range(N_nds - size):
                if not used[start:start+size].any():
                    modules.append(list(range(start, start+size)))
                    used[start:start+size] = True
                    break

    # Extra node per module
    available = np.where(~used)[0].tolist()

    for i in range(len(modules)):
        n_extra = min(n_extra_per_module, len(available))
        if n_extra > 0:
            extra_nodes = rn.sample(available, n_extra)
            modules[i].extend(extra_nodes)

            # remove availables
            for n in extra_nodes:
                available.remove(n)

    # Connectivity intra-modules
    for mod in modules:
        for i in mod:
            for j in mod:
                if i > j:
                    A[i, j] = rn.uniform(*intra_range)

    if sym:
        A = A + A.T - np.diag(np.diagonal(A))

    return A, modules
def gen_states_modular_A(S, N_nodes=90, n_modules=(3,6),
                         intra_range=(0.6,1.0),
                         n_extra_per_module=3,
                         sym=True,
                         seed=None):
  
    

    As = []
    for k in range(S):
        n_modules_diag = rn.randint(*n_modules)
        A,_ = gen_modular_A(
            N_nds=N_nodes,
            n_modules_diag=n_modules_diag,
            n_extra_per_module=n_extra_per_module,
            intra_range=intra_range,
            seed=seed,
            sym=sym
        )
        if seed is not None:
            seed += 5 

        As.append(A)

    return np.array(As)
# GENERATES THE U ARRAY WITH DYNAMIC STATES

# based in the function in BallonModelNet but with non_posible_pos added
def gen_node_stimulus(timeline, non_posible_pos, nblocks=5, duration_range=(1,3), sep_bwn_ons= 10, time_offset=10):
    N_pts = len(timeline)
    possible_onsets = np.arange(time_offset, N_pts-time_offset)
    positions_onsets = np.setdiff1d(possible_onsets, non_posible_pos)
    durations = []
    onsets = []
    for i in range(nblocks):
        current_block_duration = rn.randint(duration_range[0], duration_range[1])
        current_onset = rn.choice( possible_onsets )
        onsets.append( current_onset )
        durations.append( current_block_duration )
        possible_onsets = possible_onsets[np.logical_or( possible_onsets < current_onset - sep_bwn_ons,
                                                possible_onsets > current_onset + sep_bwn_ons)]
    u = np.zeros(N_pts)
    for i,d in zip(onsets, durations):
        u[i:i+d] = 1
    return u, timeline, onsets, durations

# Select the duration of a segment
def duration_triangular(rng, params):

    dmin, dmode, dmax = params
    # numpy triangular distribution
    dur = rng.triangular(left=dmin, mode=dmode, right=dmax)
    dur = int(np.round(dur))
    return min(dur, dmax)

# Extract tuples of the state and duration
def extract_state_durations(state_array):
    """
    Recibe un arreglo de enteros que representan el estado en cada punto de tiempo.
    Devuelve una lista de tuplas (estado, duración).
    """
    state_array = np.asarray(state_array)

    # Found index where states change
    change_points = np.where(np.diff(state_array) != 0)[0] + 1
    # add start and end to create the segment
    segment_starts = np.r_[0, change_points]
    segment_ends = np.r_[change_points, len(state_array)]

    result = []
    for start, end in zip(segment_starts, segment_ends):
        estado = state_array[start]
        duracion = end - start
        result.append((estado, duracion))

    return result
# Return list of segments of each state
def segment_indices_by_state(segments, S):
    """
    segments: [{'state': s, 'start': a, 'end': b}, ...],
    S: int, number of states
    returns:


    e.g.
    [
      [[0,1,2], [9,10,11]],     # state 0 and 2 segments
      [[17,18,19,20,21,22]],   # state 1 and 1 segment
      [[3,4,5,6,7,8]]          # ...
    ]
    """
    # an empty list for state
    segments_by_state = [[] for _ in range(S)]

    for seg in segments:
        s = seg['state']
        start = seg['start']
        end = seg['end']
        indices = list(range(start, end))   # índices del segmento
        segments_by_state[s].append(indices)

    return segments_by_state

# Generation of the states array
def gen_state_sequence(timeline, S, P, dur_params, time_offset=10, seed=None):
    """
    Generates a sequence of states

    Parameters

    timeline : array-like (N_pts,)
    S : int Número de estados (0,1,...,S-1).
    P:  SxS Tansition Matrix
    dur_params : list[()] one set contains the min, mode and max duration of the segment
    time_offset : int
    seed : int or None

    Returns

    states : np.ndarray shape (N_pts,)
    states_dur : list of tuples (state, duration)
    segments : list of dict each dict: {"state": s, "start": i0, "end": i1}
    """
    rng = np.random.default_rng(seed)
    N_pts = len(timeline)
    states = np.zeros(N_pts, dtype=int)
    segments = []

    t_idx = time_offset

    curr_state = rng.choice(list(range(S))) # Select the first state

    while t_idx < N_pts-time_offset:
        #dmin, dmax = duration_range_per_state[curr_state]
        #dur = int(rng.integers(dmin, dmax+1))
        dur = duration_triangular(rng, dur_params[curr_state])
        end = min(t_idx + dur, N_pts)
        states[t_idx:end] = curr_state
        segments.append({"state": curr_state, "start": t_idx, "end": end})
        t_idx = end
        # próxima elección de estado (simple: no repetir el mismo consecutivo)
        if S > 1:
            curr_state = rng.choice(S, p = P[curr_state]) # Select the next state based on the transition matrix
        else:
            curr_state = 0
    states[:time_offset] = states[time_offset]
    states[-time_offset:] = states[N_pts-time_offset-1]
    states_dur = extract_state_durations(states)
    segments_indx_by_states = segment_indices_by_state(segments, S)

    return states, states_dur, segments_indx_by_states


def ons_with_sep(arr, n=1):
    return sorted({x + d for x in arr for d in range(-n, n + 1)})

# Extract the active nodes of each state
def active_nodes_per_states(FC_states):
    active_nodes_per_C = []
    for C in FC_states:
        C = C.copy()
        np.fill_diagonal(C, 0)  # dont consider the diagonal
        # Conections ≠ 0
        active_nodes = np.where(np.any(C != 0, axis=0) | np.any(C != 0, axis=1))[0]
        active_nodes_per_C.append(active_nodes.tolist())
    return active_nodes_per_C # List of lists with the active nodes of each state (e.g. [[1, 2, 3, 4], [0, 1, 3, 4], [1, 2, 3, 4]])

# Selects for each segment the active node wich will generate the stimulus
def select_node_for_segment(active_nodes_per_C, segments_indx_by_states, n_nodes=2, seed = None):
    """
    Generates vector u(t) for one node

    Parameters
    ----------
    active_nodes_per_C: list of lists that contais the active nodes of each state
    segments_indx_by_states : list of lists that contais the segments of each state

    Returns
    -------
    active_node_segments : list of lists that contais the active nodes for each segment
    """
    active_node_segments = []
    random.seed(seed)
    for s in range(len(active_nodes_per_C)):
        active_nodes = active_nodes_per_C[s]
        segments = segments_indx_by_states[s]
        selected_nodes = []

        for seg in segments:
            active_nodes_copy = active_nodes.copy()
            node1 = random.choice(active_nodes_copy)
            if n_nodes == 2:
                active_nodes_copy.remove(node1)
                node2 = random.choice(active_nodes_copy)

                selected_nodes.append([node1, node2]) # select at least 2 nodes

            else:
                selected_nodes.append([node1])

        active_node_segments.append(selected_nodes)

    return active_node_segments

# Generates stimulus of a single node
def gen_node_stimulus_by_states(node, states, active_nodes, active_node_segments, nblocks_default, segments_indx_by_states, duration_stimulus_per_state,
                                sep_bwn_ons, time_offset=10, seed=None):
    """
    Generates vector u(t) for one node

    Parameters
    ----------
    node: int, Corresponding node
    states : (N_pts,) etiquetas [0..S-1]
    active_nodes: list[list] list of active nodes of states
    active_node_segments: list[list] list of the selected nodes for segments
    nblocks_default : int
    duration_stimulus_per_state : list[tuple] duration of stimulus, en TRs (min,max)
    sep_bwn_ons_per_state : list[int] largo S, separación mínima (en TRs)
    time_offset : int, margen inicial para no empezar pegado a t=0
    seed : int or None

    Returns
    -------
    u : np.ndarray (N_pts,)
    onsets, durations : list of the onsets and durations
    """
    rng = np.random.default_rng(seed)
    N_pts = len(states)
    S = np.max(states) + 1
    u = np.zeros(N_pts, dtype=float)

    onsets_all = []
    durs_all = []

    offset1 = range(time_offset)
    offset2 = range(N_pts - time_offset, N_pts)
    offsets = list(offset1) + list(offset2)

    selected = [] #onset_all copy for auxiliar function
    non_posible_pos = [] # positions that are not available

    # For each state, founds the segments
    for s in range(S):
        if node not in active_nodes[s]:
            #print("nodo no activo", node)
            continue

        # parameters of states
        dmin, dmax = duration_stimulus_per_state[s]#duration of stimulus
        sep = sep_bwn_ons

        possible_positions = segments_indx_by_states[s]
        onsets_s = []
        durs_s = []
        # It generates only one stimulus in each segment of "s" state
        for i, positions_segm in enumerate(possible_positions):

            #print("non_posible:", non_posible_pos)
            #print("positionsegm:", positions_segm)
            if node not in(active_node_segments[s][i]):
                continue

            onset = positions_segm[0] # the stimulus starts right in the begining of the state segment

            positions_segm = np.setdiff1d(positions_segm, non_posible_pos + offsets) # It eliminates positions that doesnt respect the min sep value onsets

            if ((onset not in(positions_segm)) and (positions_segm.size != 0)):
                onset = int(rng.choice(np.array(positions_segm)))

            elif len(positions_segm) == 0:
                print(f"Segmento {i} del estado {s} no representado")
                continue


            #onset = int(rng.choice(np.array(positions_segm)))
            active_node_segments[s][i] = [node]
            dur = int(rng.integers(dmin, dmax+1))
            end = min(onset + dur, N_pts)
            # on the block
            u[onset:end] = 1.0
            onsets_s.append(onset)
            durs_s.append(dur)
            selected.append(onset)
            non_posible_pos = ons_with_sep(selected, n=sep)


        onsets_all.extend(onsets_s)
        durs_all.extend(durs_s)


    if len(onsets_all) < nblocks_default:# In case the node didnt activate with any state or the stimulus are less than minimun, the stimulus will be spontaneous
        dmin, dmax = duration_stimulus_per_state[s]
        u,_ ,onsets_all, durs_all = gen_node_stimulus(states, non_posible_pos=non_posible_pos, nblocks=nblocks_default, duration_range=(dmin, dmax), sep_bwn_ons=sep_bwn_ons)


    return u, onsets_all, durs_all


# Network of stimulus
def gen_network_stimulus_by_states(timeline, states, N_nds, FC_states,
                                   nblocks_default, segments_indx_by_states, duration_stimulus_per_state,
                                   sep_bwn_ons, time_offset=10, seed=None):
    """
    Generates U(t) (N_pts x N_nds) align with the states sequence

    Parameters
    ----------
    timeline : (N_pts,)
    states   : (N_pts,) states labels
    N_nds    : int, number of ROIs
    FC_states : list[np.ndarray (N_nds, N_nds)] len S, a list of connectivity matrices
    nblocks_default : list[int] len(S)
    duration_stimulus_per_state : list[tuple] len(S)
    sep_bwn_ons_per_state : list[int] len(S)
    time_offset : int
    seed : int or None

    Returns
    -------
    U : np.ndarray (N_pts, N_nds)
    meta : list[dict]
    """
    rng = np.random.default_rng(seed)
    N_pts = len(timeline)
    U = np.zeros((N_pts, N_nds), dtype=float)
    meta = []
    active_nodes_per_C = active_nodes_per_states(FC_states)
    active_node_segments = select_node_for_segment(active_nodes_per_C, segments_indx_by_states, seed=seed)
    #print(active_node_segments)

    for node in range(N_nds):
        # Changes the seed for each ROI
        seed_n = None if seed is None else int(rng.integers(0, 1_000_000))
        u_n, on_n, du_n = gen_node_stimulus_by_states(
            node = node,
            states=states,
            active_nodes=active_nodes_per_C, # The active nodes of each state
            active_node_segments = active_node_segments, # The selected nodes for the segments
            nblocks_default=nblocks_default,
            segments_indx_by_states = segments_indx_by_states,
            duration_stimulus_per_state=duration_stimulus_per_state,
            sep_bwn_ons=sep_bwn_ons,
            time_offset=time_offset,
            seed=seed_n
        )

        U[:, node] = u_n
        meta.append({"roi": node, "onsets": on_n, "durations": du_n})
    return U, meta

# STIMULUS TO NEURAL PART

def StimulusToNeural_piecewise(timing, u, const, C_list, state_array, segm_dur,TR):
    """
    Stimulus-to-neural function with piecewise-static connectivity.

    Parameters
    ----------
    timing : array-like Original time points of the stimulus
    u : array (Nsamples, Nrois) Stimulus input
    const : float Gain factor for stimulus
    C_list : list of np.ndarray List of connectivity matrices
    state_array : array-like (len = number of timepoints after interpolation)
        Sequence of state indices, one per timepoint (e.g. [0,0,0,1,1,2,...])
    segm_dur: array-like, duration of each state
    Returns
    -------
    t_all : array Concatenated time array
    neur_all : array Neural responses concatenated across blocks
    """

    Nsamples, Nrois = u.shape
    kappa1 = 1 # before 2
    tau = 2
    N0 = 0
    newdeltat = 1

    newtiming = np.arange(min(timing), max(timing), newdeltat)
    #print(newtiming)
    # Interpolación de estímulo
    if u.ndim == 1:
        u = u[:, np.newaxis]

    newu_list = []
    for j in range(u.shape[1]):
        f_interp = interp1d(timing, u[:, j], kind='nearest')
        newu = f_interp(newtiming)
        newu_list.append(newu[:, np.newaxis] * const)
    newu = np.concatenate(newu_list, axis=1)

    interpolators = [interp1d(newtiming, newu[:, j], kind='nearest') for j in range(u.shape[1])]

    A = (1/tau) * np.eye(Nrois)
    I0 = - N0

    # Dynamic part
    I_concat = []
    t_concat = []
    I_last = Nrois * [I0]

    start = 0
    for segm in segm_dur:
        end = start + int(segm[1]*TR) # star + duration of the block
        t_seg = newtiming[start:end]
        # print(t_seg)
        C = C_list[segm[0]]  # elegir la conectividad correspondiente
        params = [kappa1, tau, N0, interpolators, A, C]
        sol = solve_ivp(neureq, [t_seg[0], t_seg[-1]], I_last, args=(params,), t_eval=t_seg, max_step=np.diff(t_seg).min()/4)
        I_concat.append(sol.y.T)
        t_concat.append(sol.t)
        I_last = sol.y[:, -1]  # Initial condition for the next block
        start = end

    I = np.vstack(I_concat)
    t_all = np.concatenate(t_concat)

    newstim = np.concatenate([f(t_all)[:, np.newaxis] for f in interpolators], axis=1)
    neur = newstim - I
    neur[neur < 0] = 0
    neur = np.clip(neur, 0, 3.0) # Buxton (1998) and Friston (2000).

    return t_all, neur

# Same function neureq in BalloonModelNet.py
def neureq(t, I, params): # Eq14 Buxton
    kappa1, tau, N0, interpolators, A, C = params
    ut = np.array([f(t) for f in interpolators])
    N = ut - C @ I
    # N = ut - I
    if np.any(N > -N0):
        dIdt = (kappa1/tau) * N - A@I
    else:
        dIdt = (-kappa1/tau) * N0 - A@I # neural response cannot go below 0
    return dIdt


# NEURAL TO FLOW
def floweq(t, y, params):
    x1, x2 = y
    kappa2, gamma, neuronalact, timing = params
    neuronal = np.interp(t, timing, neuronalact)
    derivs = [x2, neuronal-x2*kappa2-(x1-1)*gamma]
    return derivs


def NeuraltoFlow(timing, neuralresp):

    kappa2 = .65; # prior from the paper: 0.65
    gamma = .41; # prior from the paper: 0.41

    # Bundle parameters for ODE solver
    params = [kappa2, gamma, neuralresp, timing]

    # Bundle initial conditions for ODE solver
    f0 = 1. # flow in to vasculature
    s0 = 0. # signal to the vasulature
    y0 = [f0, s0]

    # Make time array for solution
    tInc = 1
    t = np.arange(timing[0], timing[-1], tInc)

    # Call the ODE solver
    # psoln = odeint(systemeq, y0, t, args=(params,))
    solver = ode(floweq).set_integrator('dopri5')
    # solver = ode(floweq).set_integrator("dop853")
    solver.set_initial_value(y0).set_f_params(params)

    k = 0
    soln = [y0]

    while solver.successful() and solver.t < t[-1]:
        k += 1
        solver.integrate(t[k])
        soln.append(solver.y)

    # Convert the list to a numpy array.
    psoln = np.array(soln)

    flow = psoln[:,0]
    vascsignal = psoln[:,1]

    return t, flow, vascsignal

def Eeq(E0, flowin):
    return 1-(1-E0)**(1/flowin)

# balloon model parameter function


def balloonparameter(TE,B0,E0,V0):

    if B0==3:
        r0 = 108
    elif B0==1.5:
        r0 = 15
    else:
        print("""Parameter value for r0 isn't available for the field strength specified, using approximation""")
        r0 = 25 *(B0/1.5)^2 # not sure where Pinglei got this from, but seems approximately correct

    if (B0==3 or B0==1.5):
        epsilon = 0.13 # assuming dominance of macrovascular component
    else:
        raise ValueError('Parameter value for epsilon is not available for the field strength specified')

    v = 40.3 * (B0/1.5)

    k1 = 4.3 * v * E0 * TE
    k2 = epsilon*r0*E0*TE
    k3 = 1 - epsilon

    return (k1, k2, k3, V0, E0)

# BALLOON MODEL PART
def systemeq(t, y, params): # system of differential equations for balloon model
    x1, x2 = y
    tau1, tau2, alpha, E0, flowin, timing = params
    f = interp1d(timing, flowin)
    fin = f(t)
    E = Eeq(E0,fin)
    derivs = [(1/tau1)*(fin*E/E0-x1/x2*(x2**(1/alpha)+tau2/(tau1+tau2)*(fin-x2**(1/alpha)))),
             1/(tau1+tau2)*(fin-(x2**(1/alpha)))]
    return derivs




# make the balloon model function

def BalloonModel(timing, flowin, TE):


    alpha = .4; # 0.32 in Friston
    E0 = 0.4;
    V0 = 0.03; # 0.03 in Buxton, Uludag, et al.
    F0 = 0.01;
    tau2 = 30; # typical value based on fits from Mildner, Norris, Schwarzbauer, and Wiggins (2001)
    B0 = 3; # we have a 3 T scanner!
    tau1 = V0/F0;
    k1, k2, k3, V0, E0 = balloonparameter(TE, B0, E0, V0);
    q0 = 1;
    v0 = 1;
    V0 = V0;

    # Bundle parameters for ODE solver
    params = [tau1, tau2, alpha, E0, flowin, timing]

    # Bundle initial conditions for ODE solver
    y0 = [q0, v0]

    # Make time array for solution
    tInc = 2.0 #TR
    t = np.arange(timing[0], timing[-1], tInc)

    # Call the ODE solver
    # psoln = odeint(systemeq, y0, t, args=(params,))
    solver = ode(systemeq).set_integrator("dop853")
    solver.set_initial_value(y0).set_f_params(params)

    k = 0
    soln = [y0]
    while solver.successful() and solver.t < t[-1]:
        k += 1
        solver.integrate(t[k])
        soln.append(solver.y)

    # Convert the list to a numpy array.
    psoln = np.array(soln)

    q = psoln[:,0]
    v = psoln[:,1]
    bold = V0*(k1*(1-q)+k2*(1-q/v)+k3*(1-v))


    return (t, bold, q, v)

# DYNAMIC BALLOON MODEL NET

def Dyn_BalloonModelNetwork(timeline, U, sample, FC_states, states_dur, P=None,TR=2):
    # Dynamic product C*U
    u_list = []
    for C in FC_states:
        u = np.transpose(C @ U.T)
        u_list.append(u)
    u_blocks = np.zeros_like(U)

    for s in range(len(FC_states)):
        idx_state_s = np.where(sample == s)[0]
        u_blocks[idx_state_s,:] = u_list[s][idx_state_s,:]

    deltat = 1
    const = 1
    Dyn_BalloonNetwork = {'timing': timeline, 'u': u_blocks, 'U':U , 'sample':sample, "FC_states":FC_states,
                  'tneur':[], 'neur':[], 'tflowin':[], 'flowin':[],
                  'vascsignal':[], 'tbold': [], 'bold':[], 'v':[], 'q':[]}

    tneur, neur = StimulusToNeural_piecewise(timing=timeline, u = u_blocks, const=const, C_list = FC_states , state_array= sample, segm_dur = states_dur, TR= TR) # stimulus to neural response
    Dyn_BalloonNetwork['tneur'] = tneur
    Dyn_BalloonNetwork['neur'] = neur
    Dyn_BalloonNetwork['tu'] = timeline
    Dyn_BalloonNetwork['u'] = u_blocks
    Dyn_BalloonNetwork['P'] = P

    TE = 0.03
    Nsamples, Nrois = neur.shape

    for inode in range(Nrois):
        #print(f'node {inode+1}')
        tflowin, flowin, vascsignal = NeuraltoFlow(tneur, neur[:, inode]) # neural to flow in
        tbold, bold, q, v = BalloonModel(tflowin, flowin, TE) # flow in to BOLD
        Dyn_BalloonNetwork['tflowin'].append(tflowin[:,np.newaxis])
        Dyn_BalloonNetwork['flowin'].append(flowin[:,np.newaxis])
        Dyn_BalloonNetwork['vascsignal'].append(vascsignal[:,np.newaxis])
        Dyn_BalloonNetwork['tbold'].append(tbold[:,np.newaxis])
        Dyn_BalloonNetwork['bold'].append(bold[:,np.newaxis])
        Dyn_BalloonNetwork['v'].append(v[:,np.newaxis])
        Dyn_BalloonNetwork['q'].append(q[:,np.newaxis])
        
    for k in Dyn_BalloonNetwork:
        vl = Dyn_BalloonNetwork[k]


        if isinstance(vl, list):
            vl = np.concatenate(vl, axis=1)
            Dyn_BalloonNetwork[k] = vl

    return Dyn_BalloonNetwork

# VISUALIZATION

def _compute_edges(t):
    #Compute the edges of the states in x
    mid = (t[:-1] + t[1:]) / 2.0
    left0  = t[0] - (mid[0] - t[0])
    rightN = t[-1] + (t[-1] - mid[-1])
    return np.concatenate(([left0], mid, [rightN]))

def shade_states(ax, timeline, sample, cmap, alpha=0.18, zorder=0):
    """
    - timeline: 1D, same dimensions of sample
    - sample:   1D, state series (ex. (1,1,1,0,0,0,2,2,2,1,1,1,0,0,0))
    - cmap:     colormap of the states
    """
    t_edges  = _compute_edges(timeline)
    states   = np.unique(sample)
    idx_of   = {s:i for i, s in enumerate(states)}

    start = 0
    curr  = sample[0]
    for k in range(1, len(sample)+1):
        if k == len(sample) or sample[k] != curr:
            left, right = t_edges[start], t_edges[k]
            color = cmap(idx_of[curr])
            ax.axvspan(left, right, facecolor=color, alpha=alpha, linewidth=0, zorder=zorder)
            if k < len(sample):
                start, curr = k, sample[k]

def plot_signal_states(timeline, tsignal, signal, D, S, FC_states, sample, TR=2, alpha=0.18, zorder=0, U=None, mode = "neur", shift=2):
    if mode == "neur":
        title = "Neural response of ROIs"
    elif mode == "bold":
        title = "Bold signal of ROIs"
        sample = np.roll(sample, shift)

    cmap = matplotlib.colormaps.get_cmap('viridis').resampled(S)
    Nrois=D
    mid = (timeline[:-1] + timeline[1:]) / 2.0
    t_edges = np.concatenate(([timeline[0] - (mid[0] - timeline[0])], mid, [timeline[-1] + (timeline[-1] - mid[-1])]))
    # Adjust figure size based on the number of ROIs and the added sample plot
    fig, axes = plt.subplots(Nrois + 1, 1, figsize=(10, Nrois * 2 + 2), gridspec_kw={'height_ratios': [2] * Nrois + [1]})
    for i in range(Nrois):
        ax = axes[i]
        shade_states(ax, timeline, sample, cmap, alpha=0.18, zorder=0)
        #ax.plot(timeline, u_blocks[:, i], label=f"Estímulo ROI {i+1}", color='tab:blue', linewidth=1.5, linestyle='--')
        if U is not None:
            ax.plot(timeline, U[:, i], label=f"Estímulo ROI {i+1}", color='tab:blue', linewidth=1.5, linestyle='--')

        ax.plot(tsignal, signal[:, i], label=f"Respuesta Neural ROI {i+1}", color='tab:red', linewidth=1.5)
        ax.set_ylabel(f"ROI {i+1} Amplitud")
        #ax.grid(alpha=0.3)
        ax.grid(False)
        ax.set_xlim(0, len(timeline)*TR)  #
        if i == 0:
            ax.set_title(title)
        if i == Nrois - 1:
            ax.set_xlabel("Tiempo (s)")
        #ax.legend()
    ax_sample = axes[-1]

    states = np.unique(sample)
    

    # Horizontal bar of the states
    pc = ax_sample.pcolormesh(t_edges,           # x borders
                              [0, 1],
                              sample.reshape(1, -1),
                              cmap=cmap,
                              shading="flat"
                              )

    ax_sample.set_title('States over time')
    ax_sample.set_xlabel('Time (s)')
    ax_sample.set_yticks([])
    #ax_sample.set_xlim(timeline[0], timeline[-1])
    plt.tight_layout()
    fig.colorbar(pc, ax=ax_sample, ticks=states, label='State')
    plt.show()


    # Figure 2 C matrices
    fig2, axes2 = plt.subplots(1, S, figsize=(6*S, 5)) # Dynamically set figure size based on S

    # Plot each C from FC_states using a loop
    if S > 1: # Check if there are multiple states to plot in separate subplots
        for i in range(S):
            sns.heatmap(FC_states[i], ax=axes2[i], cmap="viridis", annot=True, fmt=".2f")
            axes2[i].set_title(f"Connectivity matrix - State {i}")
            axes2[i].set_xlabel('ROI')
            axes2[i].set_ylabel('ROI')
    else: # If there's only one state, plot it in the single subplot
        sns.heatmap(FC_states[0], ax=axes2, cmap="viridis", annot=True, fmt=".2f")
        axes2.set_title("Connectivity matrix - State 0")
        axes2.set_xlabel('ROI')
        axes2.set_ylabel('ROI')


    plt.tight_layout()
    plt.show()